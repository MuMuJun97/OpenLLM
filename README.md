# OpenLLM
A list of Large Language Model projects ... 


## Awesome Fundamental LLMs

### [Facebook/LLaMa](https://github.com/facebookresearch/llama) 
- LLaMA: Open and Efficient Foundation Language Models, [arXiv](https://arxiv.org/abs/2302.13971v1)
- download the checkpoints and tokenizer: [link](checkpoints/LLaMa.md)
- LLaMA quick start with Python: 
```python
# TODO
```
#### pyllama 
- Single GPU Inference: https://github.com/juncongmoo/pyllama 


### ChatGLM-6B
ChatGLM-6B is a bilingual language model, which can be run on a single consumer-grade GPU.

The model is based on the GLM architecture and has 6.2 billion parameters.

ChatGLM-6B is trained on 1T identifiers in both Chinese and English, supported by supervised fine-tuning, feedback self-help, and human feedback reinforcement learning. Thus, though ChatGLM-6B is not as large as the 100 billion model, it has greatly reduced the inference cost, improved the efficiency, and has been able to generate responses that are quite consistent with human preferences.

Project repo: [https://github.com/THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)

### 
